# Hikma Engine Environment Variables Configuration
# Copy this file to .env and modify as needed

# ===========================================
# CLI Configuration
# ===========================================

# Logging level for CLI operations (debug, info, warn, error)
HIKMA_LOG_LEVEL=info

# Database configuration
HIKMA_SQLITE_PATH=./data/metadata.db
HIKMA_SQLITE_VEC_EXTENSION=./extensions/vec0.dylib

# ===========================================
# API Server Configuration
# ===========================================

# Server settings
HIKMA_API_PORT=3000
HIKMA_API_HOST=localhost
HIKMA_API_TIMEOUT=30000
HIKMA_API_MAX_REQUEST_SIZE=10mb

# CORS Configuration
HIKMA_API_CORS_ENABLED=true
HIKMA_API_CORS_ORIGINS=*
HIKMA_API_CORS_CREDENTIALS=false
HIKMA_API_CORS_METHODS=GET,POST,PUT,DELETE,OPTIONS

# Rate Limiting
HIKMA_API_RATE_LIMIT_ENABLED=true
HIKMA_API_RATE_LIMIT_WINDOW_MS=60000
HIKMA_API_RATE_LIMIT_MAX_REQUESTS=100
HIKMA_API_RATE_LIMIT_SKIP_SUCCESS=false
HIKMA_API_RATE_LIMIT_SKIP_FAILED=false

# Cache Configuration
HIKMA_API_CACHE_ENABLED=true
HIKMA_API_CACHE_TTL_SEMANTIC=900
HIKMA_API_CACHE_TTL_STRUCTURAL=1800
HIKMA_API_CACHE_TTL_GIT=3600
HIKMA_API_CACHE_TTL_HYBRID=900
HIKMA_API_CACHE_TTL_COMPREHENSIVE=1200
HIKMA_API_CACHE_MAX_SIZE=1000

# Search Configuration
HIKMA_API_SEARCH_MAX_RESULTS=100
HIKMA_API_SEARCH_DEFAULT_RESULTS=10
HIKMA_API_SEARCH_MAX_QUERY_LENGTH=500
HIKMA_API_SEARCH_MIN_SIMILARITY=0.1
HIKMA_API_SEARCH_MAX_SIMILARITY=1.0
HIKMA_API_SEARCH_RELEVANCE_THRESHOLD=0.3
HIKMA_API_SEARCH_ALLOWED_FILE_TYPES=.ts,.js,.tsx,.jsx,.py,.java,.go,.cpp,.c,.h,.cs,.php,.rb,.rs,.kt,.swift,.scala,.clj,.hs
HIKMA_API_SEARCH_EXCLUDED_DIRECTORIES=node_modules,dist,build,.git,.vscode,.idea,coverage,tmp,temp,logs
HIKMA_API_SEARCH_MAX_FILE_SIZE=1048576

# Search Enhancement
HIKMA_API_SEARCH_SYNTAX_HIGHLIGHTING=true
HIKMA_API_SEARCH_RELATED_FILES=true
HIKMA_API_SEARCH_BREADCRUMBS=true
HIKMA_API_SEARCH_RELEVANCE_EXPLANATION=true
HIKMA_API_SEARCH_MAX_CONTEXT_LINES=5

# Monitoring Configuration
HIKMA_API_MONITORING_ENABLED=true
HIKMA_API_HEALTH_CHECK_ENABLED=true
HIKMA_API_HEALTH_CHECK_INTERVAL=30000
HIKMA_API_HEALTH_CHECK_TIMEOUT=5000
HIKMA_API_METRICS_ENABLED=true
HIKMA_API_METRICS_COLLECT_INTERVAL=10000
HIKMA_API_METRICS_RETENTION_PERIOD=86400
HIKMA_API_ALERTS_ENABLED=true
HIKMA_API_ALERTS_ERROR_RATE_THRESHOLD=0.1
HIKMA_API_ALERTS_RESPONSE_TIME_THRESHOLD=5000
HIKMA_API_ALERTS_COOLDOWN_PERIOD=300

# Security Configuration
HIKMA_API_KEY_ENABLED=false
HIKMA_API_KEY_HEADER=X-API-Key
HIKMA_API_KEYS=
HIKMA_API_JWT_ENABLED=false
HIKMA_API_JWT_SECRET=
HIKMA_API_JWT_EXPIRES_IN=1h
HIKMA_API_JWT_ALGORITHM=HS256
HIKMA_API_CSP_ENABLED=true
HIKMA_API_X_FRAME_OPTIONS_ENABLED=true
HIKMA_API_X_CONTENT_TYPE_OPTIONS_ENABLED=true
HIKMA_API_REFERRER_POLICY_ENABLED=true

# API Logging
HIKMA_API_LOG_LEVEL=info
HIKMA_API_LOG_FORMAT=json
HIKMA_API_LOG_INCLUDE_REQUEST_ID=true
HIKMA_API_LOG_INCLUDE_TIMESTAMP=true
HIKMA_API_LOG_REQUESTS=true
HIKMA_API_LOG_RESPONSES=false

# ===========================================
# Additional Environment Variables
# ===========================================

# Node Environment
NODE_ENV=development

# General Server Configuration (used by some components)
PORT=3000
HOST=0.0.0.0
CORS_ORIGIN=

# Request Configuration
REQUEST_TIMEOUT=30000
SLOW_REQUEST_THRESHOLD=1000

# Rate Limiting (additional variables used in middleware)
GLOBAL_RATE_LIMIT=100
SEARCH_RATE_LIMIT=50
HEAVY_SEARCH_RATE_LIMIT=20
HEALTH_RATE_LIMIT=200
DEV_RATE_LIMIT=500

# Build and Version Information (optional)
npm_package_version=
BUILD_TIME=
GIT_COMMIT=

# ===========================================
# AI Model Configuration
# ===========================================

# Embedding model for text vectorization
# Default: mixedbread-ai/mxbai-embed-large-v1
HIKMA_EMBEDDING_MODEL=mixedbread-ai/mxbai-embed-large-v1

# Embedding provider (local, transformers, python, openai)
# Default: python (uses local Python-based embedding)
HIKMA_EMBEDDING_PROVIDER=python

# OpenAI-compatible Embedding Provider Configuration (e.g., Ollama)
# Required when HIKMA_EMBEDDING_PROVIDER=openai
# Note: For Ollama, use the base URL; the engine will call /v1/embeddings
HIKMA_EMBEDDING_OPENAI_API_URL=http://localhost:11434
HIKMA_EMBEDDING_OPENAI_API_KEY=
HIKMA_EMBEDDING_OPENAI_MODEL=mxbai-embed-large:latest

# RAG (Retrieval-Augmented Generation) model for code explanation
HIKMA_RAG_MODEL=Qwen/Qwen2.5-Coder-1.5B-Instruct

# ===========================================
# LLM Provider Configuration
# ===========================================

# LLM provider to use for code explanations (python, openai)
# Default: python (uses local Python-based LLM)
HIKMA_ENGINE_LLM_PROVIDER=python

# Request timeout in milliseconds
HIKMA_ENGINE_LLM_TIMEOUT=300000

# Number of retry attempts for failed requests
HIKMA_ENGINE_LLM_RETRY_ATTEMPTS=3

# Delay between retry attempts in milliseconds
HIKMA_ENGINE_LLM_RETRY_DELAY=1000

# OpenAI Provider Configuration (required when HIKMA_ENGINE_LLM_PROVIDER=openai)
HIKMA_ENGINE_LLM_OPENAI_API_URL=https://api.openai.com/v1/chat/completions
HIKMA_ENGINE_LLM_OPENAI_API_KEY=sk-your-openai-api-key-here
HIKMA_ENGINE_LLM_OPENAI_MODEL=gpt-4

# Optional OpenAI settings
HIKMA_ENGINE_LLM_OPENAI_MAX_TOKENS=400
HIKMA_ENGINE_LLM_OPENAI_TEMPERATURE=0.6

# Python Provider Configuration (optional, uses defaults if not specified)
HIKMA_ENGINE_LLM_PYTHON_MODEL=Qwen/Qwen2.5-Coder-1.5B-Instruct
HIKMA_ENGINE_LLM_PYTHON_MAX_RESULTS=8

# ===========================================
# Docker Configuration (optional)
# ===========================================

# Source path for indexing (used in Docker)
HIKMA_SOURCE_PATH=/app/source

# Whether to index on startup (used in Docker)
HIKMA_INDEX_ON_STARTUP=false
